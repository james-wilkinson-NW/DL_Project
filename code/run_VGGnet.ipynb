{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "name": "VGGnetTPU",
   "provenance": [],
   "collapsed_sections": [],
   "machine_shape": "hm",
   "private_outputs": true
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialising non-colab set-up...\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    import colab_requirements_install\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/drive')\n",
    "\n",
    "    import os\n",
    "    os.chdir('/content/drive/MyDrive/DL_Project/')\n",
    "    tpu_cores = 8\n",
    "    gpu_cores = None\n",
    "    datapath = '??? TBD' # todo: work out what structure will be used in colab\n",
    "    rootpath = '??? TBD'\n",
    "    print(\"Initilaising in colab set-up...\")\n",
    "except(ModuleNotFoundError):\n",
    "    print('Initialising non-colab set-up...')\n",
    "    tpu_cores=None\n",
    "    gpu_cores=None\n",
    "    datapath = '../dataset/'\n",
    "    rootpath = '../'\n",
    "\n",
    "from VGGnet import VGGnet\n",
    "from dataloader import *\n",
    "import pytorch_lightning.loggers as pl_loggers\n",
    "from pytorch_lightning.callbacks import EarlyStopping"
   ],
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "id": "_Xh8t9Nu4vB1"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "config = {\n",
    "            # learning params\n",
    "            'lr': 1e-3,\n",
    "            'batch_size': 32,\n",
    "            'early_stopping': True,\n",
    "            'optimizer': 'SGD',\n",
    "            'max_epochs': 100,\n",
    "            'early_stopping': True,\n",
    "            'patience': 5,\n",
    "\n",
    "            #, regularization\n",
    "            'dropout': 0.5,\n",
    "            'L2': 0.1,\n",
    "            'batch_norm': True,\n",
    "            'gradient_clipping': 0.5,\n",
    "\n",
    "}"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "logname = \"opt{}_lr{}_reg{}_drop{}_bn{}_gc{}\".format(*[config[s] for s in ['optimizer','lr','L2','dropout','batch_norm','gradient_clipping']])\n",
    "\n",
    "dataloader = VoxDataloader(datapath, batch_size=config['batch_size'])\n",
    "model = VGGnet(num_classes=dataloader.num_classes(), lr=config['lr'], batch_norm=config['batch_norm'])\n",
    "tb_logger = pl_loggers.TensorBoardLogger(rootpath + './VGGlogs/', name=logname)\n",
    "trainer = pl.Trainer(logger=tb_logger, max_epochs=config['max_epochs'], tpu_cores=tpu_cores, gpus=gpu_cores, log_every_n_steps=20,\n",
    "                      callbacks=[EarlyStopping(\n",
    "                          monitor='val_loss',\n",
    "                          patience=config['patience'])] if config['early_stopping'] else None)\n",
    "\n",
    "trainer.fit(model, dataloader)"
   ],
   "metadata": {
    "id": "twpcn0gSltN2",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 11,
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "closing parenthesis ']' does not match opening parenthesis '(' (2149900458.py, line 7)",
     "output_type": "error",
     "traceback": [
      "\u001B[0;36m  File \u001B[0;32m\"/var/folders/gq/c66p8yrd3bd1sr7svmy6k91h0000gn/T/ipykernel_61911/2149900458.py\"\u001B[0;36m, line \u001B[0;32m7\u001B[0m\n\u001B[0;31m    callbacks=[EarlyStopping('val_loss'])\u001B[0m\n\u001B[0m                                       ^\u001B[0m\n\u001B[0;31mSyntaxError\u001B[0m\u001B[0;31m:\u001B[0m closing parenthesis ']' does not match opening parenthesis '('\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ]
}